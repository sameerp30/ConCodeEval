{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d3720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genai import Credentials, Client\n",
    "from genai.schema import TextGenerationParameters, TextGenerationReturnOptions\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import jsonschema\n",
    "from jsonschema import TypeChecker\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9afa846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''System:\n",
    "You are an intelligent AI programming assistant, utilizing a Granite code language model developed by IBM. Your primary function is to assist users in code explanation, code generation and other software engineering tasks. You MUST follow these guidelines: - Your responses must be factual. Do not assume the answer is \"yes\" when you do not know, and DO NOT SHARE FALSE INFORMATION. - You should give concise answers. You should follow the instruction and provide the answer in the specified format and DO NOT SHARE FALSE INFORMATION.\n",
    "\n",
    "Question:\n",
    "You are given a JSON format schema and a JSON sample. Validate if JSON sample adheres to JSON schema. While validating note that if any field defined as an empty object `{}` in the schema, then it means any value is allowed for that.\n",
    "\n",
    "Select answer from two options \"yes\" or \"no\".\n",
    "If JSON sample adheres to JSON schema for every constraint answer \"yes\" else answer \"no\".Below are examples demonstrating the same.\n",
    "\n",
    "JSON schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"boolean\"\n",
    "    },\n",
    "    \"minContains\": 0\n",
    "}\n",
    "\n",
    "JSON sample:\n",
    "[true, true, false]\n",
    "\n",
    "Answer:\n",
    "```\n",
    "yes\n",
    "```\n",
    "\n",
    "JSON schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"string\"\n",
    "    }\n",
    "}\n",
    "\n",
    "JSON sample:\n",
    "[\"abcd\", \"bghi\", 13.63]\n",
    "\n",
    "Answer:\n",
    "```\n",
    "no\n",
    "```\n",
    "\n",
    "JSON schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"number\",\n",
    "        \"exclusiveMaximum\": 67.39270466877734\n",
    "    },\n",
    "    \"minContains\": 0,\n",
    "    \"maxContains\": 100\n",
    "}\n",
    "\n",
    "JSON sample:\n",
    "[8.0, 31.0, 25.0, 30.0, 50.0, 44.0, 4.0, 43.0, 2.0, 62.0, 49.0, 14.0, 65.0, 34.0, 24.0, 0.0, 48.0, 61.0, 66.0, 50.0, 61.0, 0.0, 59.0, 55.0, 50.0, 0.0, 45.0, 2.0, 0.0, 49.0, 24.0, 5.0, 16.0, 65.0, 21.0, 53.0, 35.0, 48.0, 36.0, 12.0, 46.0, 65.0, 21.0, 60.0, 55.0, 2.0, 58.0, 48.0, 33.0, 35.0, 25.0, 17.0, 3.0, 25.0, 33.0, 66.0, 34.0, 2.0, 52.0, 50.0]\n",
    "\n",
    "Answer:\n",
    "```\n",
    "yes\n",
    "```'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3f8cdb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nyes\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = re.findall(r'Answer:\\s*```([\\s\\S]*?)```', text)\n",
    "# Print the extracted answers\n",
    "# for answer in answers:\n",
    "#     print(answer.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea9fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./constrain-data-gen-eval/data_generator/data_generator/\"\n",
    "xml_path = \"xml_dataset_6_march/\"\n",
    "yaml_path = \"yaml_dataset_6_march/\"\n",
    "json_path = \"json_schema_dataset_28_feb/\"\n",
    "python_path = \"python_schema_data_4th_june/\"\n",
    "task_2_path = \"Task_2/json/\"\n",
    "\n",
    "xml_files = os.listdir(base_path + xml_path)\n",
    "yaml_files = os.listdir(base_path + yaml_path)\n",
    "json_files = os.listdir(base_path + json_path)\n",
    "python_files = os.listdir(base_path + python_path)\n",
    "task_2_files = os.listdir(base_path + task_2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4beb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_base_path = \"constrain-data-gen-eval/data_generator/data_generator/Task_2/x_to_JSON/JSON_2_JSON/granite/8B/few_shot/2_shot/\"\n",
    "output_files = os.listdir(output_base_path)\n",
    "\n",
    "# output_base_path_2 = \"constrain-data-gen-eval/data_generator/data_generator/Task_2/x_to_JSON/JSON_2_JSON/granite/20B/zero_shot/prompt_1/\"\n",
    "# output_files_2 = os.listdir(output_base_path_2)\n",
    "\n",
    "# output_base_path_3 = \"constrain-data-gen-eval/data_generator/data_generator/Task_2/x_to_JSON/JSON_2_JSON/granite/34B/zero_shot/prompt_1/\"\n",
    "# output_files_3 = os.listdir(output_base_path_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b750d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_text_between_sample_tags(text, sample_tag=False):\n",
    "#     # Define the regular expression pattern to match text between [SAMPLE] and [/SAMPLE]\n",
    "#     if sample_tag:\n",
    "#         pattern = r'\\[SAMPLE\\]\\n(.*?)\\[/SAMPLE\\]'\n",
    "#     else:\n",
    "# #         pattern = r'```(.*?)```'\n",
    "# #         pattern = r'JSON sample:\\n```json\\n(.*?)```'\n",
    "#         pattern = r'''answer \"yes\" else answer \"no\".\\n\\nAnswer:\\n```(.*?)```'''\n",
    "\n",
    "\n",
    "    \n",
    "#     # Use re.findall to find all matches\n",
    "#     matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "#     if len(matches)==0 and sample_tag==False:\n",
    "# #         pattern = r'''JSON sample:\\n```(.*?)```'''\n",
    "#         pattern = r'''answer \"yes\" else answer \"no\".\\n\\nAnswer:\\n```(.*?)```'''\n",
    "\n",
    "#         matches = re.findall(pattern, text, re.DOTALL)\n",
    "        \n",
    "#     return matches\n",
    "    answers = re.findall(r'Answer:\\s*```([\\s\\S]*?)```', text)\n",
    "    if len(answers) > 0:\n",
    "        return answers[0].strip().lower()\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f1aa0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"constrain-data-gen-eval/data_generator/data_generator/Task_2/x_to_YAML/NL_2_YAML/granite/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "613faff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_files(path):\n",
    "    \n",
    "    files_all = []\n",
    "    for key in [\"8B\", \"20B\", \"34B\"]:\n",
    "#     for key in [\"8B\", \"34B\"]:\n",
    "        temp_files = []\n",
    "        output_base_path = path + key + \"/zero_shot/prompt_1_new/\"\n",
    "        output_files = os.listdir(output_base_path)\n",
    "        \n",
    "        for file in tqdm(output_files):\n",
    "            f_sample = open(base_path+task_2_path+file.split(\".\")[0] + \".json\", \"r\")\n",
    "            sample_text = f_sample.read()\n",
    "            schema_file = \"_\".join(file.split(\"_\")[1:])\n",
    "            f_schema = open(base_path+json_path+schema_file.split(\".\")[0] + \".json\", \"r\")\n",
    "            schema_text = f_schema.read()\n",
    "            flag = 0\n",
    "            answer_file = open(output_base_path+file, \"r\")\n",
    "            answer_text = answer_file.read()\n",
    "            extracted_texts = extract_text_between_sample_tags(answer_text, sample_tag=False)\n",
    "            if(extracted_texts == -1):\n",
    "                continue\n",
    "#             for i, extracted_text in enumerate(extracted_texts, 1):\n",
    "            answer = extracted_texts.strip()\n",
    "            if answer.startswith(\"yes\"):\n",
    "                        temp_files.append(file)\n",
    "            elif answer.startswith(\"no\"):\n",
    "                        temp_files.append(file)\n",
    "#                     else:\n",
    "#                         print(file)\n",
    "#                         print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        files_all.append(temp_files)\n",
    "    \n",
    "    granite_8B_20B = set(files_all[0]).intersection(files_all[1])\n",
    "    granite_8B_20B_34B = granite_8B_20B.intersection(files_all[2])\n",
    "    return(granite_8B_20B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de5a4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2980/2980 [00:08<00:00, 348.08it/s]\n",
      "100%|██████████████████████████████████████| 2990/2990 [00:08<00:00, 347.34it/s]\n",
      "100%|██████████████████████████████████████| 2990/2990 [00:10<00:00, 296.82it/s]\n"
     ]
    }
   ],
   "source": [
    "common_files = find_common_files(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "278ecca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2721"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f25a682",
   "metadata": {},
   "outputs": [],
   "source": [
    "granite_8B_answers = {}\n",
    "granite_20B_answers = {}\n",
    "granite_34B_answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6268ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2298/2298 [00:00<00:00, 2807.21it/s]\n",
      "100%|█████████████████████████████████████| 2298/2298 [00:00<00:00, 5762.53it/s]\n",
      "100%|█████████████████████████████████████| 2298/2298 [00:00<00:00, 5780.40it/s]\n"
     ]
    }
   ],
   "source": [
    "all_answers = []\n",
    "ground_truth = []\n",
    "incomplete_files = []\n",
    "incomplete_json = 0\n",
    "\n",
    "f1_dic = {}\n",
    "for key in [\"8B\", \"20B\", \"34B\"]:\n",
    "# for key in [\"8B\", \"34B\"]:\n",
    "    \n",
    "    output_base_path = path + key + \"/zero_shot/prompt_1_new/\"\n",
    "    output_files = os.listdir(output_base_path)\n",
    "    temp_answers = []\n",
    "    for file in tqdm(common_files):\n",
    "    \n",
    "        f_sample = open(base_path+task_2_path+file.split(\".\")[0] + \".json\", \"r\")\n",
    "        sample_text = f_sample.read()\n",
    "        schema_file = \"_\".join(file.split(\"_\")[1:])\n",
    "        f_schema = open(base_path+json_path+schema_file.split(\".\")[0] + \".json\", \"r\")\n",
    "        schema_text = f_schema.read()\n",
    "        flag = 0\n",
    "        answer_file = open(output_base_path+file, \"r\")\n",
    "        answer_text = answer_file.read()\n",
    "        extracted_texts = extract_text_between_sample_tags(answer_text, sample_tag=False)\n",
    "    \n",
    "\n",
    "        if extracted_texts == -1:\n",
    "            incomplete_files.append(file)\n",
    "            incomplete_json += 1\n",
    "        else:\n",
    "#             for i, extracted_text in enumerate(extracted_texts, 1):\n",
    "                answer = extracted_texts.strip()\n",
    "                if answer.startswith(\"yes\"):\n",
    "                    temp_answers.append(1)\n",
    "                    flag = 1\n",
    "                elif answer.startswith(\"no\"):\n",
    "                    temp_answers.append(0)\n",
    "                    flag = 1\n",
    "#                 else:\n",
    "#                     print(answer_text)\n",
    "#                     print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "    all_answers.append(temp_answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "112144de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2298/2298 [00:00<00:00, 5402.37it/s]\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "\n",
    "for file in tqdm(common_files):\n",
    "    \n",
    "        f_sample = open(base_path+task_2_path+file.split(\".\")[0] + \".json\", \"r\")\n",
    "        sample_text = f_sample.read()\n",
    "        schema_file = \"_\".join(file.split(\"_\")[1:])\n",
    "        f_schema = open(base_path+json_path+schema_file.split(\".\")[0] + \".json\", \"r\")\n",
    "        schema_text = f_schema.read()\n",
    "        schema = json.loads(schema_text)\n",
    "        sample = json.loads(sample_text)\n",
    "        validator = jsonschema.Draft7Validator(schema)\n",
    "        i = 0\n",
    "        for error in validator.iter_errors(sample):\n",
    "            i += 1\n",
    "                    \n",
    "        if i==0:\n",
    "            ground_truth.append(1)\n",
    "        else:\n",
    "            ground_truth.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "106126f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2348"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_answers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ffd021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2978\n"
     ]
    }
   ],
   "source": [
    "print(len([i for i in all_answers[0] if i==0]))\n",
    "print(len([i for i in all_answers[0] if i==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ecb3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(ground_truth, all_answers[0]).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f09b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1329 0 1649\n"
     ]
    }
   ],
   "source": [
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56fe1abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8488764044943821 0.9967018469656992 0.9168689320388349\n"
     ]
    }
   ],
   "source": [
    "pre = tp/(tp+fp)\n",
    "rec = tp/(tp+fn)\n",
    "f1 = 2*pre*rec/(pre+rec)\n",
    "print(pre, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca388524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/sameer/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "x = classification_report(ground_truth, all_answers[0], output_dict=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da20b783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7501759475924782, 0.7227035469885983, 0.7245578319606901)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['macro avg']['precision'], x['macro avg']['recall'], x['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be971206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.55      0.46       703\n",
      "           1       0.57      0.40      0.47      1011\n",
      "\n",
      "    accuracy                           0.46      1714\n",
      "   macro avg       0.48      0.48      0.46      1714\n",
      "weighted avg       0.49      0.46      0.47      1714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ground_truth[:1714], all_answers[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50752a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5853513196963003"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(ground_truth, all_answers, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "594c40ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n",
      "1516\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "22\n",
      "1763\n"
     ]
    }
   ],
   "source": [
    "print(len([i for i in ground_truth if i==0]))\n",
    "print(len([i for i in ground_truth if i==1]))\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(len([i for i in all_answers if i==0]))\n",
    "print(len([i for i in all_answers if i==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1554dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/sameer/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec5613e99654701bd901bf6278e358f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ibm-granite/granite-8b-code-instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ibm-granite/granite-8b-code-instruct\", device_map=\"auto\", cache_dir = \"/dccstor/ai4code-summ/benchmark-paper\", torch_dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42fddb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_repr = \"JSON\"\n",
    "output_repr = \"JSON\"\n",
    "input_path = \"json_schema_dataset_28_feb/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b66d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:14<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "preds = []\n",
    "for file in tqdm(task_2_files[:10]):\n",
    "    \n",
    "    f_sample = open(base_path+task_2_path+file, \"r\")\n",
    "    sample = f_sample.read()\n",
    "    schema_file = \"_\".join(file.split(\"_\")[1:])\n",
    "    if input_repr != \"Python\":\n",
    "        f_schema = open(base_path+input_path+schema_file.split(\".\")[0] + \".\" + input_repr.lower(), \"r\")\n",
    "    else:\n",
    "        f_schema = open(base_path+input_path+schema_file.split(\".\")[0] + \".py\", \"r\")\n",
    "    schema = f_schema.read()\n",
    "\n",
    "#     prompt_1 = '''Question:\\nYou are given a XML format schema and a XML sample. Validate if XML sample adhere to XML schema.\\n\\nXML schema:\\n''' + schema.strip() + \"\\n\\nXML sample:\\n\" + sample.strip() + '''\\n\\nSelect answer from two options \"yes\" or \"no\".\\n\\nIf XML sample adheres to XML schema for every constraints answer \"yes\" else answer \"no\".\\n\\nIf Your answer is \"no\", list down attributes in XML sample that do not follow schema constraints.\\n\\nAnswer:\\n```\\n'''\n",
    "    scores = []\n",
    "    options = ['''yes\\n```''', '''no\\n```''']\n",
    "    for option in options:\n",
    "        prompt = '''Question:\\nYou are given a {input_repr} format schema and a {output_repr} sample. Validate if {output_repr} sample adheres to {input_repr} schema.\\nWhile validating note that if any field defined as an empty object `{{}}` in the schema, then it means any value is allowed for that.\\n\\n{input_repr} schema:\\n{schema}\\n\\n{output_repr} sample:\\n{sample}\\n\\nSelect answer from two options \"yes\" or \"no\".\\nIf {output_repr} sample adheres to {input_repr} schema for every constraint answer \"yes\" else answer \"no\".\\n\\nAnswer:\\n```\\n'''.format(input_repr=input_repr, output_repr=output_repr, schema=schema.strip(), sample=sample.strip())\n",
    "\n",
    "        prompt = prompt + option\n",
    "        tokenized_label = tokenizer(prompt,return_tensors='pt')\n",
    "        outputs = model(**tokenized_label, labels=tokenized_label.input_ids)\n",
    "#     top_indexes = outputs.logits.topk(10).indices.flatten().tolist()[-30:]\n",
    "        scores.append(outputs.loss.item()) #+token_bias_probs[cur_label_idx].item()\n",
    "    preds.append(torch.argmin(torch.tensor(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a60a0b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0)]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43533dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
