{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jsonschema\n",
    "from jsonschema import TypeChecker\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import xmltodict, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_between_sample_tags(text, sample_tag=False):\n",
    "    # Define the regular expression pattern to match text between [SAMPLE] and [/SAMPLE]\n",
    "    if sample_tag:\n",
    "        pattern = r'\\[SAMPLE\\]\\n(.*?)\\[/SAMPLE\\]'\n",
    "    else:\n",
    "        # pattern = r'```XML sample:(.*?)```'\n",
    "        # pattern = r'Answer:\\n```json\\n(.*?)```'\n",
    "        # pattern = r'''JSON sample:\\n```json\\n(.*?)```'''\n",
    "        # pattern = r'''JSON sample:\\n```(.*?)```'''\n",
    "        pattern = r'''```(.*?)```'''\n",
    "\n",
    "    \n",
    "    # Use re.findall to find all matches\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    if len(matches)==0 and sample_tag==False:\n",
    "        # pattern = r'''Answer:\\n```(.*?)```'''\n",
    "        # pattern = r'''JSON sample:\\n```(.*?)```'''\n",
    "        pattern = r'''```(.*?)```'''\n",
    "        # pattern = r'```json(.*?)```'\n",
    "\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(d, prefix='schema'):\n",
    "    paths = []\n",
    "    for key, value in d.items():\n",
    "        if prefix:\n",
    "            new_key = f'''{prefix}['{key}']'''\n",
    "        else:\n",
    "            new_key = key\n",
    "        paths.append(new_key)\n",
    "        if isinstance(value, dict):\n",
    "            paths.extend(get_paths(value, new_key))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_base_path = \"/raid/nlp/sameer/conCodeEval/all_data/dccstor/ai4code-summ/benchmark-paper/backup/constrain-data-gen-eval/data_generator/data_generator/Task_1/x_to_JSON/JSON_2_JSON/granite/34B/zero_shot/prompt_1/\"\n",
    "output_base_path = \"/raid/nlp/sameer/conCodeEval/all_data/dccstor/ai4code-summ/benchmark-paper/backup/constrain-data-gen-eval/data_generator/data_generator/Task_1/x_to_JSON/JSON_2_JSON/codellama/70B/zero_shot/prompt_2/\"\n",
    "\n",
    "output_json_files = os.listdir(output_base_path)\n",
    "\n",
    "base_path = \"/raid/nlp/sameer/conCodeEval/all_data/dccstor/ai4code-summ/benchmark-paper/backup/constrain-data-gen-eval/data_generator/data_generator/\"\n",
    "json_schema_path = \"json_schema_dataset_28_feb/\"\n",
    "xml_schema_path = \"xml_dataset_6_march/\"\n",
    "yaml_schema_path = \"yaml_dataset_6_march/\"\n",
    "manual_NL_path = \"manual_NL_summary/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "invalid_json = 0\n",
    "incomplete_json = 0\n",
    "type_violation = 0\n",
    "file_name_errors = {}\n",
    "incomplete_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function divides the schema constraints in starting 20%, end 20%, and rest middle\n",
    "def bucketing_constraints(all_keys_string):\n",
    "    begin = len(all_keys_string)/5\n",
    "    end = len(all_keys_string) - len(all_keys_string)/5\n",
    "    begin_constraints = []\n",
    "    mid_constraints = []\n",
    "    end_constraints = []\n",
    "    for i in range(0,len(all_keys_string)):\n",
    "        if i < begin:\n",
    "            begin_constraints.append(all_keys_string[i])\n",
    "        elif i >= end:\n",
    "            end_constraints.append(all_keys_string[i])\n",
    "        else:\n",
    "            mid_constraints.append(all_keys_string[i])\n",
    "\n",
    "    return begin_constraints, mid_constraints, end_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 602/602 [00:00<00:00, 4537.99it/s]\n"
     ]
    }
   ],
   "source": [
    "invalid_json, incomplete_json = 0, 0\n",
    "\n",
    "incomplete_files = []\n",
    "total_begin_errors, total_mid_errors, total_end_errors = [], [], []\n",
    "\n",
    "for file in tqdm(output_json_files):\n",
    "    if file.endswith(\".txt\") == False:\n",
    "        continue\n",
    "        \n",
    "    f_output = open(output_base_path+file, \"r\")\n",
    "    text = f_output.read().split('<|eot_id|><|start_header_id|>assistant<|end_header_id|>')[1]\n",
    "    f_schema = open(base_path+json_schema_path+file.split(\".\")[0] + \".json\", \"r\")\n",
    "    schema_text = f_schema.read()\n",
    "    schema = json.loads(schema_text)\n",
    "    all_keys_string = get_paths(schema)\n",
    "    begin_constraints, mid_constraints, end_constraints = bucketing_constraints(all_keys_string)\n",
    "    extracted_texts = extract_text_between_sample_tags(text.strip(), sample_tag=False)\n",
    "    if len(extracted_texts) == 0:\n",
    "        incomplete_files.append(file)\n",
    "        incomplete_json += 1\n",
    "    else:\n",
    "        for i, extracted_text in enumerate(extracted_texts, 1):\n",
    "            try:\n",
    "                json_sample = extracted_text.strip()\n",
    "                if json_sample.startswith(\".json\"):\n",
    "                    json_sample = \"\\n\".join(json_sample.split(\"\\n\")[1:])\n",
    "#                 json_sample = json.dumps(yaml.safe_load(json_sample), default=str)\n",
    "                # json_sample = json.dumps(xmltodict.parse(json_sample), default=str)\n",
    "#                 o = xmltodict.parse('<e> <a>text</a> <a>text</a> </e>')\n",
    "                gen_json = json.loads(json_sample)\n",
    "                validator = jsonschema.Draft7Validator(schema)\n",
    "                i = 0\n",
    "                begin_errors, mid_errors, end_errors = 0, 0, 0\n",
    "                for error in validator.iter_errors(gen_json):\n",
    "                    error_str = str(error)\n",
    "                    error_tokens = error_str.split(\"\\n\\n\")[1].split()\n",
    "                    actual_error = error_tokens[4][:-1]+\"[\"+error_tokens[2]+\"]\"\n",
    "\n",
    "                    if actual_error in begin_constraints:\n",
    "                        begin_errors += 1\n",
    "                    if actual_error in mid_constraints:\n",
    "                        mid_errors += 1\n",
    "                    if actual_error in end_constraints:\n",
    "                        end_errors += 1\n",
    "\n",
    "                total_begin_errors.append(begin_errors)\n",
    "                total_end_errors.append(end_errors)\n",
    "                total_mid_errors.append(mid_errors)\n",
    "                errors.append(i)\n",
    "            except:\n",
    "                invalid_json += 1\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199, 160, 57)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_begin_errors), sum(total_mid_errors), sum(total_end_errors) #granite 8b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NL2bash",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
