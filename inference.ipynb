{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43bc11d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /u/sameer/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7beaf39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/sameer/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adc1ba8832d4fa5b18ab7b72f4b1e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/sameer/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-Instruct-hf\", cache_dir=\"/dccstor/ai4code-summ/benchmark-paper\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd9efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 21 03:29:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              69W / 400W |   6475MiB / 81920MiB |      0%   E. Process |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   26C    P0              67W / 400W |   7557MiB / 81920MiB |      0%   E. Process |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000000:44:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              68W / 400W |   7557MiB / 81920MiB |      0%   E. Process |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000000:4A:00.0 Off |                    0 |\n",
      "| N/A   30C    P0              70W / 400W |   6475MiB / 81920MiB |      0%   E. Process |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   1052964      C   /u/sameer/anaconda3/bin/python             6462MiB |\n",
      "|    1   N/A  N/A   1052964      C   /u/sameer/anaconda3/bin/python             7544MiB |\n",
      "|    2   N/A  N/A   1052964      C   /u/sameer/anaconda3/bin/python             7544MiB |\n",
      "|    3   N/A  N/A   1052964      C   /u/sameer/anaconda3/bin/python             6462MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79b1f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = \"./constrain-data-gen-eval/data_generator/data_generator/\"\n",
    "xml_path = \"xml_dataset_6_march/\"\n",
    "yaml_path = \"yaml_dataset_6_march/\"\n",
    "json_path = \"json_schema_dataset_28_feb/\"\n",
    "\n",
    "xml_files = os.listdir(base_path + xml_path)\n",
    "yaml_files = os.listdir(base_path + yaml_path)\n",
    "json_files = os.listdir(base_path + json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa51823",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "155a4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_few_shot = '''Your task is to write a JSON sample with field values as per JSON format schema.\n",
    "The JSON sample must be between [SAMPLE] and [/SAMPLE] tags.\n",
    "You are given a few examples demonstrating the same.\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"string\"\n",
    "    }\n",
    "}\n",
    "JSON sample:\n",
    "[SAMPLE]\n",
    "[\n",
    "    \"string1\",\n",
    "    \"string2\",\n",
    "    \"string3\"\n",
    "]\n",
    "[/SAMPLE]\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"string\",\n",
    "    \"format\": \"duration\",\n",
    "    \"minLength\": 0,\n",
    "    \"maxLength\": 50\n",
    "}\n",
    "JSON sample:\n",
    "[SAMPLE]\n",
    "\"P1Y2M10DT2H30M\"\n",
    "[/SAMPLE]\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"number\",\n",
    "    \"exclusiveMinimum\": 0,\n",
    "    \"exclusiveMaximum\": 10\n",
    "}\n",
    "JSON sample:\n",
    "[SAMPLE]\n",
    "67.89\n",
    "[/SAMPLE]\n",
    "\n",
    "JSON format schema:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74019840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                              | 0/5 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|█████████████████▏                                                                    | 1/5 [00:53<03:35, 53.77s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|██████████████████████████████████▍                                                   | 2/5 [01:50<02:46, 55.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|███████████████████████████████████████████████████▌                                  | 3/5 [02:47<01:52, 56.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|████████████████████████████████████████████████████████████████████▊                 | 4/5 [03:40<00:55, 55.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 5/5 [04:34<00:00, 54.91s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "for file in tqdm(json_files):\n",
    "    f = open(base_path+json_path+file, \"r\")\n",
    "    schema = f.read()\n",
    "    prompt = prompt_few_shot + schema + '''\\nJSON sample:\\n[SAMPLE]\\n'''\n",
    "#     prompt = '''[INST] Write JSON sample with field values as per the schema given in JSON format below.\\n''' + '''The JSON sample must be between [SAMPLE] and [/SAMPLE] tags.\\n\\n''' + schema + '''\\n[/INST]\\n[SAMPLE]\\n```\\n'''\n",
    "#     prompt = '''Write a JSON sample with field values as per the JSON format schema given below.''' + \"\\n\\n\" + schema + \"\\n\\nJSON sample:\\n```\"\n",
    "#     prompt = \"Question:\\n \" + \"Write a JSON sample as per the JSON format schema given below.\\n\" + schema + \" \\n Answer:\\n```\"\n",
    "#     prompt = '''This is a schema given in JSON format\\n\\nJSON format schema:\\n''' + schema + \"\\n\\nWrite a JSON sample with field values as per JSON format schema.\\nThe JSON sample must be between [SAMPLE] and [/SAMPLE] tags.\\n\\nJSON sample:\\n\"\n",
    "#     prompt = '''Write a JSON sample with field values as per the XML format schema given below.\\n\\nXML format schema:\\n''' + schema + '''\\n\\nJSON sample:\\n```\\n'''\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs, max_new_tokens=1000, num_beams=3)\n",
    "    output_text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    f_opt = open(\"./constrain-data-gen-eval/data_generator/data_generator/json_outputs/codellama/7B/few_shot/\" + file, \"w\")\n",
    "    f_opt.write(output_text)\n",
    "    f_opt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3aa50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = '''{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"number\",\n",
    "        \"multipleOf\": 47.07\n",
    "    },\n",
    "    \"maxContains\": 100\n",
    "}'''\n",
    "\n",
    "prompt = \"Question:\\n \" + \"Write a JSON sample as per the JSON format schema given below.\\n\" + schema + \" \\n Answer:\\n```\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"composite_0_10_object_i_12.xml\"\n",
    "f = open(base_path+xml_path+file, \"r\")\n",
    "schema = f.read()\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1469252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to write a JSON sample with field values as per JSON format schema.\n",
      "The JSON sample must be between [SAMPLE] and [/SAMPLE] tags.\n",
      "You are given a few examples demonstrating the same.\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"array\",\n",
      "    \"contains\": {\n",
      "        \"type\": \"string\"\n",
      "    }\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "[\n",
      "    \"string1\",\n",
      "    \"string2\",\n",
      "    \"string3\"\n",
      "]\n",
      "[/SAMPLE]\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"string\",\n",
      "    \"format\": \"duration\",\n",
      "    \"minLength\": 0,\n",
      "    \"maxLength\": 50\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "\"P1Y2M10DT2H30M\"\n",
      "[/SAMPLE]\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"number\",\n",
      "    \"exclusiveMinimum\": 0,\n",
      "    \"exclusiveMaximum\": 10\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "67.89\n",
      "[/SAMPLE]\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"array\",\n",
      "    \"items\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"pyrobitumen\": {\n",
      "                \"type\": \"number\"\n",
      "            },\n",
      "            \"heretication\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"precipices\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"solvement\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"unblamably\": {},\n",
      "            \"spastics\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"hoosh\": {},\n",
      "            \"unsplit\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"dermatophytic\": {\n",
      "                \"type\": \"string\",\n",
      "                \"format\": \"time\"\n",
      "            },\n",
      "            \"heartening\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"empyromancy\": {},\n",
      "            \"nostomanic\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"retund\": {},\n",
      "            \"upperclassman\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"dethronable\": {},\n",
      "            \"geisothermal\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"autoinhibited\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"petrochemical\": {},\n",
      "            \"importunes\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"msl\": {},\n",
      "            \"hemianopic\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"procerity\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"microlepidopter\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"pullalue\": {},\n",
      "            \"haloa\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"sipers\": {},\n",
      "            \"brache\": {},\n",
      "            \"nonactuality\": {},\n",
      "            \"indamins\": {\n",
      "                \"type\": \"string\",\n",
      "                \"format\": \"relative-json-pointer\"\n",
      "            },\n",
      "            \"sympathised\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"iterative\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"clumsiest\": {},\n",
      "            \"biggity\": {},\n",
      "            \"desiccant\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"hundredpenny\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"siphoneae\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"jough\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"sexradiate\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"subtepidness\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"flavorous\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"rigidist\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"rousseauist\": {\n",
      "                \"type\": \"string\",\n",
      "                \"format\": \"duration\",\n",
      "                \"maxLength\": 59\n",
      "            },\n",
      "            \"ridgepoled\": {},\n",
      "            \"physiologic\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"mujtahid\": {},\n",
      "            \"discriminativeness\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"greets\": {\n",
      "                \"type\": \"number\"\n",
      "            },\n",
      "            \"homothallic\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"megalocardia\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"dishwashings\": {},\n",
      "            \"unhygienic\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"fusobteria\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"praelects\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"retrogressive\": {\n",
      "                \"type\": \"null\"\n",
      "            }\n",
      "        },\n",
      "        \"additionalProperties\": true\n",
      "    }\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Your task is to write a JSON sample with field values as per JSON format schema.\n",
    "The JSON sample must be between [SAMPLE] and [/SAMPLE] tags.\n",
    "You are given a few examples demonstrating the same.\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"string\"\n",
    "    }\n",
    "}\n",
    "JSON sample:\n",
    "[SAMPLE]\n",
    "[\n",
    "    \"string1\",\n",
    "    \"string2\",\n",
    "    \"string3\"\n",
    "]\n",
    "[/SAMPLE]\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"string\",\n",
    "    \"format\": \"duration\",\n",
    "    \"minLength\": 0,\n",
    "    \"maxLength\": 50\n",
    "}\n",
    "JSON sample:\n",
    "[SAMPLE]\n",
    "\"P1Y2M10DT2H30M\"\n",
    "[/SAMPLE]\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"number\",\n",
    "    \"exclusiveMinimum\": 0,\n",
    "    \"exclusiveMaximum\": 10\n",
    "}\n",
    "JSON sample:\n",
    "[SAMPLE]\n",
    "67.89\n",
    "[/SAMPLE]\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"pyrobitumen\": {\n",
    "                \"type\": \"number\"\n",
    "            },\n",
    "            \"heretication\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"precipices\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"solvement\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"unblamably\": {},\n",
    "            \"spastics\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"hoosh\": {},\n",
    "            \"unsplit\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"dermatophytic\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"time\"\n",
    "            },\n",
    "            \"heartening\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"empyromancy\": {},\n",
    "            \"nostomanic\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"retund\": {},\n",
    "            \"upperclassman\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"dethronable\": {},\n",
    "            \"geisothermal\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"autoinhibited\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"petrochemical\": {},\n",
    "            \"importunes\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"msl\": {},\n",
    "            \"hemianopic\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"procerity\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"microlepidopter\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"pullalue\": {},\n",
    "            \"haloa\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"sipers\": {},\n",
    "            \"brache\": {},\n",
    "            \"nonactuality\": {},\n",
    "            \"indamins\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"relative-json-pointer\"\n",
    "            },\n",
    "            \"sympathised\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"iterative\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"clumsiest\": {},\n",
    "            \"biggity\": {},\n",
    "            \"desiccant\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"hundredpenny\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"siphoneae\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"jough\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"sexradiate\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"subtepidness\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"flavorous\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"rigidist\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"rousseauist\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"duration\",\n",
    "                \"maxLength\": 59\n",
    "            },\n",
    "            \"ridgepoled\": {},\n",
    "            \"physiologic\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"mujtahid\": {},\n",
    "            \"discriminativeness\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"greets\": {\n",
    "                \"type\": \"number\"\n",
    "            },\n",
    "            \"homothallic\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"megalocardia\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"dishwashings\": {},\n",
    "            \"unhygienic\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"fusobteria\": {\n",
    "                \"type\": \"null\"\n",
    "            },\n",
    "            \"praelects\": {\n",
    "                \"type\": \"boolean\"\n",
    "            },\n",
    "            \"retrogressive\": {\n",
    "                \"type\": \"null\"\n",
    "            }\n",
    "        },\n",
    "        \"additionalProperties\": true\n",
    "    }\n",
    "}\n",
    "JSON sample:\n",
    "[SAMPLE]\n",
    "'''\n",
    "print(prompt)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, max_new_tokens=1000, num_beams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7309aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"demofile2.txt\", \"r\")\n",
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d87d1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to write a JSON sample with field values as per JSON format schema.\n",
      "You are given a few examples demonstrating the same.\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"array\",\n",
      "    \"contains\": {\n",
      "        \"type\": \"string\"\n",
      "    }\n",
      "}\n",
      "JSON sample:\n",
      "```\n",
      "[\n",
      "    \"string1\",\n",
      "    \"string2\",\n",
      "    \"string3\"\n",
      "]\n",
      "```\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"string\",\n",
      "    \"format\": \"uri-reference\"\n",
      "}\n",
      "JSON sample:\n",
      "```\n",
      "\"https://example.com/path/to/resource\"\n",
      "```\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"number\"\n",
      "}\n",
      "JSON sample:\n",
      "```\n",
      "42\n",
      "```\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"array\",\n",
      "    \"contains\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"animation\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"helipad\": {},\n",
      "            \"zoopsychology\": {\n",
      "                \"type\": \"null\"\n",
      "            }\n",
      "        },\n",
      "        \"additionalProperties\": true\n",
      "    },\n",
      "    \"maxContains\": 10\n",
      "}   \n",
      "JSON sample:\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = '''Your task is to write a JSON sample with field values as per JSON format schema.\n",
    "You are given a few examples demonstrating the same.\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"string\"\n",
    "    }\n",
    "}\n",
    "JSON sample:\n",
    "```\n",
    "[\n",
    "    \"string1\",\n",
    "    \"string2\",\n",
    "    \"string3\"\n",
    "]\n",
    "```\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"string\",\n",
    "    \"format\": \"uri-reference\"\n",
    "}\n",
    "JSON sample:\n",
    "```\n",
    "\"https://example.com/path/to/resource\"\n",
    "```\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"number\"\n",
    "}\n",
    "JSON sample:\n",
    "```\n",
    "42\n",
    "```\n",
    "\n",
    "JSON format schema:\n",
    "{\n",
    "    \"type\": \"array\",\n",
    "    \"contains\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"animation\": {\n",
    "                \"type\": \"string\"\n",
    "            },\n",
    "            \"helipad\": {},\n",
    "            \"zoopsychology\": {\n",
    "                \"type\": \"null\"\n",
    "            }\n",
    "        },\n",
    "        \"additionalProperties\": true\n",
    "    },\n",
    "    \"maxContains\": 10\n",
    "}   \n",
    "JSON sample:\n",
    "```\n",
    "'''\n",
    "print(prompt)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, max_length=1000, num_beams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97692675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your task is to write a JSON sample with field values as per JSON format schema.\n",
      "The JSON sample must be between [SAMPLE] and [/SAMPLE] tags.\n",
      "You are given a few examples demonstrating the same.\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"array\",\n",
      "    \"contains\": {\n",
      "        \"type\": \"string\"\n",
      "    }\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "[\n",
      "    \"string1\",\n",
      "    \"string2\",\n",
      "    \"string3\"\n",
      "]\n",
      "[/SAMPLE]\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"string\",\n",
      "    \"format\": \"duration\",\n",
      "    \"minLength\": 0,\n",
      "    \"maxLength\": 50\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "\"P1Y2M10DT2H30M\"\n",
      "[/SAMPLE]\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"number\",\n",
      "    \"exclusiveMinimum\": 0,\n",
      "    \"exclusiveMaximum\": 10\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "67.89\n",
      "[/SAMPLE]\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"array\",\n",
      "    \"items\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"pyrobitumen\": {\n",
      "                \"type\": \"number\"\n",
      "            },\n",
      "            \"heretication\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"precipices\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"solvement\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"unblamably\": {},\n",
      "            \"spastics\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"hoosh\": {},\n",
      "            \"unsplit\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"dermatophytic\": {\n",
      "                \"type\": \"string\",\n",
      "                \"format\": \"time\"\n",
      "            },\n",
      "            \"heartening\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"empyromancy\": {},\n",
      "            \"nostomanic\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"retund\": {},\n",
      "            \"upperclassman\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"dethronable\": {},\n",
      "            \"geisothermal\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"autoinhibited\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"petrochemical\": {},\n",
      "            \"importunes\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"msl\": {},\n",
      "            \"hemianopic\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"procerity\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"microlepidopter\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"pullalue\": {},\n",
      "            \"haloa\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"sipers\": {},\n",
      "            \"brache\": {},\n",
      "            \"nonactuality\": {},\n",
      "            \"indamins\": {\n",
      "                \"type\": \"string\",\n",
      "                \"format\": \"relative-json-pointer\"\n",
      "            },\n",
      "            \"sympathised\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"iterative\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"clumsiest\": {},\n",
      "            \"biggity\": {},\n",
      "            \"desiccant\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"hundredpenny\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"siphoneae\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"jough\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"sexradiate\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"subtepidness\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"flavorous\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"rigidist\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"rousseauist\": {\n",
      "                \"type\": \"string\",\n",
      "                \"format\": \"duration\",\n",
      "                \"maxLength\": 59\n",
      "            },\n",
      "            \"ridgepoled\": {},\n",
      "            \"physiologic\": {\n",
      "                \"type\": \"string\"\n",
      "            },\n",
      "            \"mujtahid\": {},\n",
      "            \"discriminativeness\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"greets\": {\n",
      "                \"type\": \"number\"\n",
      "            },\n",
      "            \"homothallic\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"megalocardia\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"dishwashings\": {},\n",
      "            \"unhygienic\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"fusobteria\": {\n",
      "                \"type\": \"null\"\n",
      "            },\n",
      "            \"praelects\": {\n",
      "                \"type\": \"boolean\"\n",
      "            },\n",
      "            \"retrogressive\": {\n",
      "                \"type\": \"null\"\n",
      "            }\n",
      "        },\n",
      "        \"additionalProperties\": true\n",
      "    }\n",
      "}\n",
      "JSON sample:\n",
      "[SAMPLE]\n",
      "[\n",
      "    {\n",
      "        \"pyrobitumen\": 0,\n",
      "        \"heretication\": false,\n",
      "        \"precipices\": \"string\",\n",
      "        \"solvement\": null,\n",
      "        \"unblamably\": {},\n",
      "        \"spastics\": true,\n",
      "        \"hoosh\": {},\n",
      "        \"unsplit\": false,\n",
      "        \"dermatophytic\": \"00:00:00\",\n",
      "        \"heartening\": null,\n",
      "        \"empyromancy\": {},\n",
      "        \"nostomanic\": null,\n",
      "        \"retund\": {},\n",
      "        \"upperclassman\": null,\n",
      "        \"dethronable\": {},\n",
      "        \"geisothermal\": null,\n",
      "        \"autoinhibited\": \"string\",\n",
      "        \"petrochemical\": {},\n",
      "        \"importunes\": null,\n",
      "        \"msl\": {},\n",
      "        \"hemianopic\": \"string\",\n",
      "        \"procerity\": null,\n",
      "        \"microlepidopter\": true,\n",
      "        \"pullalue\": {},\n",
      "        \"haloa\": \"string\",\n",
      "        \"sipers\": {},\n",
      "        \"brache\": {},\n",
      "        \"nonactuality\": {},\n",
      "        \"indamins\": \"string\",\n",
      "        \"sympathised\": null,\n",
      "        \"iterative\": true,\n",
      "        \"clumsiest\": {},\n",
      "        \"biggity\": {},\n",
      "        \"desiccant\": \"string\",\n",
      "        \"hundredpenny\": \"string\",\n",
      "        \"siphoneae\": null,\n",
      "        \"jough\": true,\n",
      "        \"sexradiate\": false,\n",
      "        \"subtepidness\": \"string\",\n",
      "        \"flavorous\": \"string\",\n",
      "        \"rigidist\": true,\n",
      "        \"rousseauist\": \"P1Y2M10DT2H30M\",\n",
      "        \"ridgepoled\": {},\n",
      "        \"physiologic\": \"string\",\n",
      "        \"mujtahid\": {},\n",
      "        \"discriminativeness\": true,\n",
      "        \"greets\": 0,\n",
      "        \"homothallic\": false,\n",
      "        \"megalocardia\": null,\n",
      "        \"dishwashings\": {},\n",
      "        \"unhygienic\": null,\n",
      "        \"fusobteria\": null,\n",
      "        \"praelects\": true,\n",
      "        \"retrogressive\": null\n",
      "    }\n",
      "]\n",
      "[/SAMPLE]\n",
      "\n",
      "JSON format schema:\n",
      "{\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "        \"pyrobitumen\": {\n",
      "            \"type\": \"number\"\n",
      "        },\n",
      "        \"heretication\": {\n",
      "            \"type\": \"boolean\"\n",
      "        },\n",
      "        \"precipices\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"solvement\": {\n",
      "            \"type\": \"null\"\n",
      "        },\n",
      "        \"unblamably\": {},\n",
      "        \"spastics\": {\n",
      "            \"type\": \"boolean\"\n",
      "        },\n",
      "        \"hoosh\": {},\n",
      "        \"unsplit\": {\n",
      "            \"type\": \"boolean\"\n",
      "        },\n",
      "        \"dermatophytic\": {\n",
      "            \"type\": \"string\",\n",
      "            \"format\": \"time\"\n",
      "        },\n",
      "        \"heartening\": {\n",
      "            \"type\": \"null\"\n",
      "        },\n",
      "        \"empyromancy\": {},\n",
      "        \"nostomanic\": {\n",
      "            \"type\": \"null\"\n",
      "        },\n",
      "        \"retund\": {},\n",
      "        \"upperclassman\": {\n",
      "            \"type\": \"null\"\n",
      "        },\n",
      "        \"dethronable\": {},\n",
      "        \"geisothermal\": {\n",
      "            \"type\": \"null\"\n",
      "        },\n",
      "        \"autoinhibited\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"petrochemical\": {},\n",
      "        \"importunes\": {\n",
      "            \"type\": \"null\"\n",
      "        },\n",
      "        \"msl\": {},\n",
      "        \"hemianopic\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"procerity\": {\n",
      "            \"type\": \"null\"\n",
      "        },\n",
      "        \"microlepidopter\": {\n",
      "            \"type\": \"boolean\"\n",
      "        },\n",
      "        \"pullalue\": {},\n",
      "        \"haloa\": {\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"sipers\": {},\n",
      "        \"brache\": {},\n",
      "        \"nonactuality\": {},\n",
      "        \"indamins\": {\n",
      "            \"type\": \"\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(output, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4ad1017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt directories created successfully in zero_shot folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "main_dir = '/dccstor/ai4code-summ/benchmark-paper/backup/constrain-data-gen-eval/data_generator/data_generator/Task_2/x_to_YAML'\n",
    "sub_dirs = ['YAML_2_YAML', 'JSON_2_YAML', 'XML_2_YAML', 'Python_2_YAML']\n",
    "codellama_sub_dir = 'codellama'\n",
    "model_folders = ['34B', '8B', '70B']\n",
    "zero_shot_sub_dir = 'zero_shot'\n",
    "prompt_folders = ['prompt_2']\n",
    "\n",
    "# Add prompt directories inside zero_shot directories\n",
    "for sub_dir in sub_dirs:\n",
    "    codellama_path = os.path.join(main_dir, sub_dir, codellama_sub_dir)\n",
    "    \n",
    "    for model_folder in model_folders:\n",
    "        zero_shot_path = os.path.join(codellama_path, model_folder, zero_shot_sub_dir)\n",
    "        \n",
    "        # Check if the zero_shot directory exists\n",
    "        if os.path.exists(zero_shot_path):\n",
    "            for prompt_folder in prompt_folders:\n",
    "                prompt_path = os.path.join(zero_shot_path, prompt_folder)\n",
    "                os.makedirs(prompt_path, exist_ok=True)\n",
    "\n",
    "print(\"Prompt directories created successfully in zero_shot folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85549f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
